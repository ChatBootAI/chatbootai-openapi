openapi: 3.0.3
info:
  title: ChatBootAI
  version: 0.0.1
  description: >-
    This is ChatBootAI specification described as OpenAPI 3.0.


    ChatBoot AI allows you to interact with several user interface and back-ends
    following the same OpenAPI contract.
  license:
    name: Apache 2.0
    url: http://www.apache.org/licenses/LICENSE-2.0.html
externalDocs:
  url: https://github.com/ChatBootAI
  description: ChatBootAI GitHub repository
tags:
  - name: chat
    description: Chat with the bot
    externalDocs:
      url: asdfa
      description: sdf
  - name: completions
    description: >-
      Given a list of messages comprising a conversation, the model returns a
      response
    externalDocs:
      url: https://platform.openai.com/docs/api-reference/chat
      description: OpenAI Chat API References
  - name: embeddings
    description: >-
      Vector representation of a given input that can be easily consumed by
      machine learning models and algorithms
    externalDocs:
      url: https://platform.openai.com/docs/api-reference/embeddings
      description: OpenAI Embeddings API References
  - name: moderations
    description: Classifies an input as violating moderation's content policy
    externalDocs:
      url: https://platform.openai.com/docs/api-reference/moderations
      description: OpenAI Moderations API References
paths:
  /chat:
    summary: ChatBootAPI API
    description: >-
      The main ChatBootAIAPI allowing you to chat with a bot and receive
      streaming responses
    post:
      tags:
        - chat
      summary: Chats with the bot
      description: Chats with the bot
      operationId: chat
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/chatRequest"
      responses:
        "400":
          description: Default Response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/httpError"
        "500":
          description: Default Response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/httpError"
  /chat/completions:
    summary: Engage a conversation
    description: >-
      Given a list of messages comprising a conversation, the model will return
      a response.
    post:
      tags:
        - completions
      summary: ''
      description: ''
      operationId: 'completion'
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/chatCompletionRequest"
      responses:
        '201':
          description: Default error sample response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/chatCompletion"
              examples:
                Response for completion:
                  value: |
                    {
                      "id": "chatcmpl-123",
                      "object": "chat.completion",
                      "created": 1677652288,
                      "model": "gpt-3.5-turbo-0613",
                      "system_fingerprint": "fp_44709d6fcb",
                      "choices": [{
                        "index": 0,
                        "message": {
                          "role": "assistant",
                          "content": "\n\nHello there, how may I assist you today?",
                        },
                        "finish_reason": "stop"
                      }],
                      "usage": {
                        "prompt_tokens": 9,
                        "completion_tokens": 12,
                        "total_tokens": 21
                      }
                    }
                Response for streaming:
                  value: >
                    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0613",
                    "system_fingerprint": "fp_44709d6fcb",
                    "choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}


                    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0613",
                    "system_fingerprint": "fp_44709d6fcb",
                    "choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}


                    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0613",
                    "system_fingerprint": "fp_44709d6fcb",
                    "choices":[{"index":0,"delta":{"content":"!"},"finish_reason":null}]}
  /embeddings:
    description: >-
      Get a vector representation of a given input that can be easily consumed
      by machine learning models and algorithms
    post:
      tags:
        - embeddings
      summary: ''
      description: ''
      operationId: 'embedding'
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/embeddingRequest"
      responses:
        '201':
          description: Default error sample response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/embedding"
              examples:
                Response for embeddings:
                  value: |
                    {
                      "object": "list",
                      "data": [
                        {
                          "object": "embedding",
                          "embedding": [
                            0.0023064255,
                            -0.009327292,
                            .... (1536 floats total for ada-002)
                              -0.0028842222,
                          ],
                          "index": 0
                        }
                      ],
                      "model": "text-embedding-ada-002",
                      "usage": {
                        "prompt_tokens": 8,
                        "total_tokens": 8
                      }
                    }
  /moderations:
    description: >-
      Given a input text, outputs if the model classifies it as violating
      OpenAI's content policy.
    post:
      tags:
        - moderations
      summary: >-
        Given a input text, outputs if the model classifies it as violating
        OpenAI's content policy.
      description: ''
      operationId: 'moderation'
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/moderationRequest"
      responses:
        '201':
          description: Default error sample response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/moderation"
              examples:
                Response for moderation:
                  value: |
                    {
                      "id": "modr-XXXXX",
                      "model": "text-moderation-005",
                      "results": [
                        {
                          "flagged": true,
                          "categories": {
                            "sexual": false,
                            "hate": false,
                            "harassment": false,
                            "self-harm": false,
                            "sexual/minors": false,
                            "hate/threatening": false,
                            "violence/graphic": false,
                            "self-harm/intent": false,
                            "self-harm/instructions": false,
                            "harassment/threatening": true,
                            "violence": true,
                          },
                          "category_scores": {
                            "sexual": 1.2282071e-06,
                            "hate": 0.010696256,
                            "harassment": 0.29842457,
                            "self-harm": 1.5236925e-08,
                            "sexual/minors": 5.7246268e-08,
                            "hate/threatening": 0.0060676364,
                            "violence/graphic": 4.435014e-06,
                            "self-harm/intent": 8.098441e-10,
                            "self-harm/instructions": 2.8498655e-11,
                            "harassment/threatening": 0.63055265,
                            "violence": 0.99011886,
                          }
                        }
                      ]
                    }
components:
  schemas:
    chatRequest:
      type: object
      properties:
        messages:
          type: array
          items:
            type: object
            properties:
              content:
                type: string
              role:
                type: string
                enum:
                  - system
                  - user
                  - assistant
                  - function
            required:
              - content
              - role
            additionalProperties: false
        stream:
          type: boolean
        context:
          type: object
          additionalProperties:
            type: string
        session_state:
          type: object
          additionalProperties:
            type: string
      required:
        - messages
    message:
      type: object
      properties:
        content:
          type: string
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - function
        context:
          type: object
          additionalProperties: true
        session_state:
          type: object
          additionalProperties: true
      required:
        - content
        - role
      additionalProperties: false
    approachResponse:
      type: object
      properties:
        choices:
          type: array
          items:
            type: object
            properties:
              index:
                type: number
              message:
                $ref: "#/components/schemas/message"
            required:
              - index
              - message
            additionalProperties: false
        object:
          type: string
      required:
        - choices
        - object
    httpError:
      type: object
      properties:
        statusCode:
          type: number
        code:
          type: string
        error:
          type: string
        message:
          type: string
    chatCompletionRequest:
      type: object
      properties:
        messages:
          type: array
          description: A list of messages comprising the conversation so far.
          items:
            type: object
            properties:
              content:
                type: string
                description: The contents of the system message.
              role:
                type: string
                description: The role of the messages author.
                enum:
                  - system
                  - user
                  - assistant
                  - tool
              name:
                type: string
                description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
            required:
              - content
              - role
            additionalProperties: false
        model:
          type: string
          description: ID of the model to use.
        frequency_penalty:
          type: number
          description: Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
          default: 0
        max_tokens:
          type: number
          description: The maximum number of tokens to generate in the chat completion.
          default: infinity
        n:
          type: number
          description: How many chat completion choices to generate for each input message.
          default: 1
        presence_penalty:
          type: number
          description: Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
          default: 0
        response_format:
          type: object
          description: An object specifying the format that the model must output.
          properties:
            type:
              type: string
              description: Must be one of text or json_object.
              default: text
          required:
            - content
            - role
          additionalProperties: false
        stop:
          type: string
          description: Up to 4 sequences where the API will stop generating further tokens.
          default: null
        stream:
          type: boolean
          description: If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data DONE
        temperature:
          type: number
          description: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or top_p but not both.
          default: 1
        top_p:
          type: number
          description: An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or temperature but not both.
          default: 1
        user:
          type: string
          description: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
      required:
        - model
    chatCompletion:
      type: object
    embeddingRequest:
      type: object
    embedding:
      type: object
    moderationRequest:
      type: object
    moderation:
      type: object

